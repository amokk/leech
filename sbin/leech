#!/bin/sh

# Author: Aleksey Tulinov <aleksey.tulinov@gmail.com>
# Contributor: SumolX <https://github.com/SumolX>

usage() {
    echo "Usage: CONFIG_DIR=\"<DIRECTORY>\" DOWNLOADS_DIR=\"<DIRECTORY>\" $0"
    echo "Or you could omit DOWNLOADS_DIR to download files to current directory."
}

RFC822TOUNIX="$(dirname $0)/rfc822tounix"
CONFIG="$CONFIG_DIR/default"

if [ ! -f $CONFIG ]; then
    echo "ERROR: No config file found at $CONFIG"
    echo
    usage
    exit 1
fi

. $CONFIG

# sanity check
#
if [ ! -f "$XSL_TEMPLATE" ]; then
    echo "ERROR: No XSL template at \"$XSL_TEMPLATE\""
    echo "You probably need to reinstall leech."
    exit 1
fi

if [ ! -f "$FOODS" ]; then
    echo "ERROR: No feeds file at \"$FOODS\""
    echo
    usage
    exit 1
fi

if [ ! -f "$DOWNLOADS" ]; then
    echo "ERROR: No downloads file at \"$DOWNLOADS\""
    echo
    usage
    exit 1
fi

# defaults
#
if [ -z "$DOWNLOADS_DIR" ]; then
    echo "WARNING: DOWNLOADS_DIR is not set. Assuming it's current directory."
    DOWNLOADS_DIR=.
fi

if [ -z "$DOWNLOAD_RECIPE" ]; then
    DOWNLOAD_RECIPE="leech-default"
fi

if [ -z "$TMP" ]; then
    TMP=$DOWNLOADS_DIR
fi

if [ -z "$PERSISTENCE" ]; then
    PERSISTENCE=$DOWNLOADS_DIR
fi

DB="$PERSISTENCE/.leech.db"

if [ -z "$EXPIRATION" ]; then
    EXPIRATION=1 # day
fi

# set expiration in seconds
EXPIRATION=$(($EXPIRATION * 86400)) # days * seconds in a day

if [ -z "$HISTORY" ]; then
    HISTORY=14 # day
fi

# set history in seconds
HISTORY=$(($HISTORY * 86400)) # days * seconds in a day

if [ -z "$DOWNLOAD_DELAY" ]; then
    DOWNLOAD_DELAY=5
fi

if [ -z "$TIMEOUT" ]; then
    TIMEOUT=30 # seconds
fi

# temporary file with RSS-feed
LUNCH="$TMP/leech.lunch.$$"

# cURL options
#
CURL_LUNCH_OPTS="-s -f --connect-timeout $TIMEOUT --max-time $TIMEOUT" # cURL options for downloading lunch
CURL_DOWNLOADS_OPTS="$CURL_LUNCH_OPTS -C -" # cURL options for downloading files
# -s for silent, no output
# -f for not outputting failed downloads to files
# --connect_timeout and --max-time for timeouting, default value (30 secs) should be enough for torrent files, otherwise download will continue on next try
# -C - to continue incomplete downloads
#
# Notes:
# --retry doesn't really work with -C - for cURL: http://curl.haxx.se/docs/knownbugs.html

# misc options
#
GREP_OPTS="-i -E" # ignore case, extended regular expressions
SED_OPTS="-r -e"     # enable extended regular expressions
SED_REGEX=".* (.+) \"(.+)\"$" # \1 is URL, \2 is datetime in RFC822
XSLT_OPTS="--novalid" # skip loading DTDs during XSL transformation

# persistence options
#
DB_REGEX="(.+) (.+)" # \1 is md5, \2 is timestamp

# config processing
#
GREP_FILTER_COMMENTS="^\s*[^#]" # skip lines that start with # or empty

# prepare environment
#

# create tmp dir
if [ ! -d "$TMP" ]; then
    echo "WARNING: Temporary directory \"$TMP\" doesn't exist, creating it."
    mkdir -p "$TMP"
    if [ ! $? -eq 0 ]; then
        exit 1
    fi
fi

# create downloads dir
if [ ! -d "$DOWNLOADS_DIR" ]; then
    echo "WARNING: Downloads directory \"$DOWNLOADS_DIR\" doesn't exist, creating it."
    mkdir -p "$DOWNLOADS_DIR"
    if [ ! $? -eq 0 ]; then
        exit 1
    fi
fi

if [ ! -d "$PERSISTENCE" ]; then
    echo "WARNING: Persistence directory \"$PERSISTENCE\" doesn't exist, creating it"
    mkdir -p "$PERSISTENCE"
    if [ ! $? -eq 0 ]; then
        exit 1
    fi
fi

# current time
NOW=$(date -u +%s)

# remove previous lunch if any
rm -f "$LUNCH"

# downloading
#
cat "$FOODS" | grep -re $GREP_FILTER_COMMENTS | while read FOOD
do
    # download lunch
    #
    echo -n "Downloading feed: $FOOD... "
    curl $CURL_LUNCH_OPTS "$FOOD" >"$LUNCH"
    RET=$?

    # don't parse lunch if download failed
    #
    case $RET in
        0)
            echo "OK"
            ;;

        *)
            echo "Failed: $RET"
            rm -f "$LUNCH"
            continue
            ;;
    esac

    # search lunch for patterns
    #
    cat "$DOWNLOADS" | grep -re $GREP_FILTER_COMMENTS | while read -r PATTERN # -r to read backslashes
    do
        # download urls if any
        #
        xsltproc $XSLT_OPTS "$XSL_TEMPLATE" "$LUNCH" | grep $GREP_OPTS "$PATTERN" | while read STR
        do
            URL=$(echo $STR | sed $SED_OPTS "s/$SED_REGEX/\1/")

            if [ -z "$URL" ]; then
                continue
            fi

            # timestamp in RSS is in RFC822 format, it need to be converted to string understandable by `date`
            TIMESTAMP=$(echo $STR | sed $SED_OPTS "s/$SED_REGEX/\2/")
            UNIXTIME=$($RFC822TOUNIX "$TIMESTAMP")
            if [ ! $? -eq 0 ]; then
                echo "WARNING: RSS timestamp ($TIMESTAMP) can't be parsed correctly, expiration feature might not work properly"
                UNIXTIME=""
            fi

            # check RSS entry pub date
            if [ ! -z "$UNIXTIME" ] && [ $(($NOW - $UNIXTIME)) -gt $EXPIRATION ]; then
                echo "Skipping $URL: expired"
                continue
            fi

            MD5=$(expr substr "$(echo -n "$URL" | md5sum)" 1 32) #"

            # check md5 of URL for duplicates
            grep "$MD5" "$DB" >/dev/null 2>&1
            if [ $? -eq 0 ]; then
                echo "Skipping $URL: already downloaded"
                continue
            fi

            echo -n "Downloading: $URL... "
            sleep $DOWNLOAD_DELAY

            (LEECH_TMP="$TMP" \
             LEECH_DOWNLOADS_DIR="$DOWNLOADS_DIR" \
             LEECH_TIMEOUT="$TIMEOUT" \
             LEECH_URL="$URL" \
             LEECH_URL_MD5="$MD5" \
             $DOWNLOAD_RECIPE >/dev/null 2>&1)

            RET=$?

            case $RET in
                0)
                    echo "OK"
                    ;;
                *)
                    echo "Failed: $RET"
                    continue
                    ;;
            esac

            # make a record in DB about downloaded file
            echo "$MD5 $NOW" >>"$DB"
        done
    done

    # cleanup
    #
    rm -f "$LUNCH"
done

# delete old records from DB
#
if [ -f "$DB" ]; then
    DB_TMP="$DB.tmp"
    rm -f "$DB_TMP" && touch "$DB_TMP"

    # write new database to tmp file
    while read LINE
    do
        TIMESTAMP=$(echo "$LINE" | sed $SED_OPTS "s/$DB_REGEX/\2/")
        if [ $(($NOW - $TIMESTAMP)) -gt $HISTORY ]; then
            continue
        fi

        echo "$LINE" >>"$DB_TMP"
    done <"$DB"

    # replace db with new one
    if [ -f "$DB_TMP" ]; then
        mv "$DB_TMP" "$DB"
    fi
fi
